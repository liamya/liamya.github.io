---
layout: post
title: "AI Part 2: Don't fear AI"
author: William Wong
categories: uni
---

### Intro
Hi there! This will be a continuation of my first blog post where I talked about the question “is AI is harmful or helpful”. You can read the first blog post [here](https://liamya.github.io/).
Let’s review what my first post was about: I concluded that AI becoming evil is not possible. The reason for that is that general artificial intelligence is needed for that scenario. I also concluded that AI only becomes harmful if we humans intentionally make it harmful.
I am writing the second part here after the AI1 course at ZHAW. 

The question now is: do I still hold the same views as before?

### Evil AI nowhere near
Not too surprisingly, I do still hold the same view: AI will not become evil. Consciousness and human’s thoughts are still not really understandable at the moment. 
The chance that AI will suddenly develop spontaneous malicious intent is therefore not possible at all. From the course I also learnt consciousness does not really matter at all to create intelligent systems. So what else are people afraid of? 

### Generative adversarial network (GAN)
Let me tell you about the generative adversarial networks. I am not an expert in this field but I found this concept quite interesting. I chose this concept because it actually reminds me of the fictional scenario where AI competes against other AI and improve each other during their mutual training. If you want to read more about it, click here: [Generative Adversarial Networks — Explained](https://towardsdatascience.com/generative-adversarial-networks-explained-34472718707a).

How it works:

<div style="text-align:center"><img src="/assets/GAN_concept.png" width="60%" /></div>


In this concept a generator is used to generate for example real-looking images and the discriminator is trying to identify which one is fake. It is similar to a game where the one tries to fool the other and the other one tries to not be fooled. The core idea is that the generator is being trained by the discriminator, which itself is also being trained. 

With this concept, GAN is trained to generate e.g images or videos which look authentic to human eyes. And if you try to look for applications on the web, there are plenty of them:

<div style="text-align:center"><img src="/assets/google_search.png" width="50%" /></div>



**Upscaling resolution in video games**

GAN have been for example used to recreate old video games in a higher resolution via image training. 
[Article: Final fantasy 7 makeover](https://www.pcgamer.com/ai-neural-networks-are-giving-final-fantasy-7-a-makeover/)

<div style="text-align:center"><img src="/assets/gan_resolution.gif" width="40%" /></div>

While retaining the original level of features, a clearer and sharper texture is being recreated with better quality than the original. It’s cool and useful but not scary.

**Generating faces**

What about [faces](https://generated.photos/faces) of humans who don’t even exist? 
Because we cannot tell the difference, it is indeed a little bit disturbing. After all, these faces are from humans who don’t exist. Maybe photo models go out of work?

**Fake videos**

Well, what about realistic [videos](https://www.vice.com/en/article/qv7zkw/create-fake-videos-of-faces-samsung-ai-labs-algorithm) of you ? 
In this example they only need one photo to create an animated portraits of you. Obviously this is already more frightening. Let’s say someone creates a fake video of you and puts in on the internet with some altered audio of you saying ignorant things.

<div style="text-align:center"><img src="/assets/monalisa.gif" width="60%" /></div>

**Art**

At least they cannot create creative things like [art](https://deepart.io/) or music pieces, right? I guess we were wrong.

Some systems can turn photos into an artwork with a chosen stylistic elements:

<div style="text-align:center"><img src="/assets/tech_2016.jpg" width="30%" /><img src="/assets/sternenacht.jpg" width="30%" /></div>

<div style="text-align:center"><img src="/assets/tech_art.jpg" width="60%" /></div>

**Fear**

Did I impress you with these examples? Because functions are mentioned that are to some degree impressive and maybe disturbing, fear is being created. Naturally, humans start to make assumptions and predictions about our future. People start to generalize what AI can do and think that anything can be generated with GAN. E.g AI starts to generate their own faces and create fake media and fake news to start war and humanity is doomed. If you want more horror stories look at this article: [Five of the scariest predictions about artificial intelligence](https://www.cnbc.com/2018/08/01/five-of-the-scariest-predictions-for-ai.html)

### The catch with predictions

There are countless articles on how AI will take over the world or causing mass unemployment. The problem with these predictions are that they create fear and keep us from working productively. Let me tell you about the seven deadly sins of AI predictions.

1.	Overestimating and underestimating
2.	Imagining magic
3.	Performance versus competence
4.	Suitcase words
5.	Exponentials
6.	Hollywood scenarios
7.	Speed of deployment

If you want to read more about them click [here](https://www.technologyreview.com/2017/10/06/241837/the-seven-deadly-sins-of-ai-predictions/).

**Why did I mention them?**

Humans have the past of making wrong predictions. In my opinion this case is the same with AI. The numerous benefits and unimaginable potential are obvious, but there are people who worry about things that are not going to happen. The seven deadly sins are some reasons why wrong predictions happen and I think before reading any article about new innovations we should maybe consider the seven deadly sins.

### Mass unemployement

[This article](https://www.marketwatch.com/story/this-chart-spells-out-in-black-and-white-just-how-many-jobs-will-be-lost-to-robots-2017-05-31?mg=prod/accounts-mw) for example claims that robots will take over half of today’s jobs in 10-20 years. Articles like these catch the attention our eyes very quickly simple due to the fact that something not understandable **takes something away** from us.

Rodnes Brooks explains that this is an example of mistaken prediction due to the seven deadly sins. 
He quotes:
>  “Almost all innovations in robotics and AI take far, far, longer to be really widely deployed than people in the field and outside the field imagine.“

Humans fear what they do not understand and very quickly make assumptions about the short-term future. It was the same in the early 1950s when the age of the computer arrived. People feared that any unskilled job would be replaced by the computer in the next years. And until today new technology has always been the scapegoat to blame joblessness.

Here are some previous headlines of articles ranging from 1950 to 1980. You can find more of them on this [article](https://timeline.com/robots-have-been-about-to-take-all-the-jobs-for-more-than-200-years-5c9c08a2f41d):

<div style="text-align:center"><img src="/assets/1950_headline.png" width="30%" /><img src="/assets/1960_headline.png" width="30%" /><img src="/assets/1980_headline.png" width="30%" />

If we look back about these articles we can conclude that the fear was unreasonable. It is true that jobs will be replaced but we tend to forget that new technologies open up new opportunities and also create new jobs. The goal of AI is to **improve the life of workers and not replace them** and there is absolutely no robot in this world who wants to “steal” your job.   

### Conclusion

I agree that there are some examples where AI can be a threat. (Look at previous blog post where I talked about biased AI). But we should not forget that almost all innovations take far longer than people imagine. They will evolve over time and the changes in our society will not be sudden and unexpected as many people think. Making possible future assumptions are good, but creating fear and hysteria in short-term future is not productive. It is better to look what is possible in right now and don’t overestimate it. Let’s try to create norms to prevent threats which are possible with current AI.  Prepare schools and change education systems so that students learn skills which cannot be easily replaced by narrow AI. 
