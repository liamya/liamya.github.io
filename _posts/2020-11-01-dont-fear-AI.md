---
layout: post
title: "AI Part 2: Don't fear AI"
author: William Wong
categories: uni
published: false
---

### Intro
Hi there! This will be a continuation of my first blog post where I talked about the question “is AI is harmful or helpful”. You can read the first blog post [here](https://liamya.github.io/).
Let’s review what my first post was about: I concluded that AI becoming evil is not possible. The reason for that is that general artificial intelligence is needed for that scenario. I also concluded that AI only becomes harmful if we humans intentionally make it harmful.
I am writing the second part here after the AI1 course at ZHAW. 

The question now is: do I still hold the same views as before?

### Evil AI nowhere near
Not too surprisingly, I do still hold the same view: AI will not become evil. Consciousness and human’s thoughts are still not really understandable at the moment. 
The chance that AI will suddenly develop spontaneous malicious intent is therefore not possible at all. From the course I also learnt consciousness does not really matter at all to create intelligent systems. So what else are people afraid of? 

### Generative adversarial network (GAN)
Let me tell you about the generative adversarial networks. I am not an expert in this field but I found this concept quite interesting. I chose this concept because it actually reminds me of the fictional scenario where AI competes against other AI and improve each other during their mutual training. If you want to read more about it, click here: [Generative Adversarial Networks — Explained](https://towardsdatascience.com/generative-adversarial-networks-explained-34472718707a).

How it works:

<div style="text-align:center"><img src="/assets/GAN_concept.png" width="60%" /></div>

In this concept a generator is used to generate for example real-looking images and the discriminator is trying to identify which one is fake. It is similar to a game where the one tries to fool the other and the other one tries to not be fooled. The core idea is that the generator is being trained by the discriminator, which itself is also being trained. 

With this concept, GAN is trained to generate e.g images or videos which look authentic to human eyes. And if you try to look for applications on the web, there are plenty of them:

<div style="text-align:center"><img src="/assets/google_search.png" width="60%" /></div>

**Upscaling resolution in video games**

GAN have been for example used to recreate old video games in a higher resolution via image training. 
[Article: Final fantasy 7 makeover](https://www.pcgamer.com/ai-neural-networks-are-giving-final-fantasy-7-a-makeover/)

<div style="text-align:center"><img src="/assets/gan_resolution.gif" width="40%" /></div>

While retaining the original level of features, a clearer and sharper texture is being recreated with better quality than the original. It’s cool and useful but not scary.

**Generating faces**

What about [faces](https://generated.photos/faces) of humans who don’t even exist? 
Because we cannot tell the difference, it is indeed a little bit disturbing. After all, these faces are from humans who don’t exist. Maybe photo models go out of work?

**Fake videos**

Well, what about realistic [videos](https://www.vice.com/en/article/qv7zkw/create-fake-videos-of-faces-samsung-ai-labs-algorithm) of you ? 
In this example they only need one photo to create an animated portraits of you. Obviously this is already more frightening. Let’s say someone creates a fake video of you and puts in on the internet with some altered audio of you saying ignorant things.

**Art**

At least they cannot create creative things like [art](https://deepart.io/) or music pieces, right? I guess we were wrong:
<div style="text-align:center"><img src="/assets/tech_2016.jpg" width="40%" /></div>
<div style="text-align:center"><img src="/assets/sternenacht.jpg" width="40%" /></div>
<div style="text-align:center"><img src="/assets/tech_art.jpg" width="40%" /></div>
