---
layout: post
---

![Postimage](/assets/ai_vs_human.jpg)

### Background

Without a doubt, Artificial Intelligence is one of the most discussed topics right now. With the rise of self-driving cars, virtual assistants and even humanoid robots, AI is becoming part of our everyday life. Even though AI is programmed to do something beneficial, many people are afraid of AI and even believe that we are going to die because of it. Opinions are very different and they range from “AI can save our world” to “AI will kill us all”.


In this blog post I will try give answer to the question: “is AI helpful or harmful”. Obviously, there is no way to summarize such a broad topic on just a few pages. That’s why I will focus on my opinion and try keep it short. I also have to mention, that I am still new to this topic, so if there is anything you want to add or you disagree with, I would love to read your opinion in the comments. Most of the sources that I used can be found here: [Discussion paper: Whats wrong with AI?](https://sisr.swissinformatics.org/si-magazine-dirk-helbing-whats-wrong-with-ai-a-discussion-paper/).


On top of that, there will be another part of this blog after my first semester of KI1 – hopefully with more insights! I hope you can enjoy reading the first part!

#### "AI is improving at an unpredictable rate"

To get started, we have to consider think about makes people afraid of AI. You have probably seen this scenario in movies, where AI is programmed to do something useful, but is improving so quickly to the point, where it stops listening to humans and silently kills us. 


If you look at past AI systems for playing strategic games, you can tell how much progress has been made in the last 20 years. For instance, Google’s AlphaGo system beat the 18-time world champion Lee Sedol in Go in 2016 - this is about 10 to 20 years earlier than many experts expected this to happen. Since we simply do not know, how fast AI is progressing, being concerned is natural reaction. But it gets even more interesting with AlphaZero, which managed to outperform AlphaGo **without** human training - only by playing Go against itself. 

#### "How intelligent is AI?"

It’s obvious that these AI systems perform exceptionally at one task. However, they are still not able to feel emotions, so humans are still more intelligent, right? Humans think and feel, while computers process information – but how different are these two things apart? Will AI ever reach human-like brain power? I really don’t know the answer to that and I hope I can get a better idea with this course.

#### "Using AI to manipulate us"

AI becoming super intelligent and evil is one concern, but what about current AI, which can influence our behavior already? With AI having our personal information, it is obvious that these data can be used to manipulate us. Amazon, Google and other companies have been using machine learning algorithms to recommend products in order to increase sales for years, and it is clearly working very well. Selling a product might not be an absolutely severe threat, but what if AI would be used for political reasons? With the revelations of Edward Snowden, we know that we have been targets of mass surveillance [source](https://emerj.com/ai-future-outlook/nsa-surveillance-and-sentient-world-simulation-exploiting-privacyto-
predict-the-future/). It is already reality that our data has not only been used for marketing, but also to manipulate elections. When people use AI for selfish reasons, AI becomes a dangerous weapon instead of something valuable to our society. In my opinion, it is the fault of humankind and not of AI that something like this happened.

#### "This or that?"

AI is capable of finding paths to solutions that no humans would be capable of, which makes them ideal to help making decisions. This makes room for humans to focus on more important matters. However, we cannot leave the whole decision making to the AI, while humans lie in the sun. AI is not always trustable. Not because they are evil, but because they are typically trained with data of the past and this can be extremely problematic. According to [this article](https://rm.coe.int/discrimination-artificial-intelligence-and-algorithmic-decision-making/1680925d73/) a computer program has been developed to sort out applications of students at a medical school. The training data for the program were admission files from earlier years. It turned out that the program discriminated against women and against people with an immigrant background, because the program reproduced the bias from the data it was trained with. 

#### "How much can we trust AI?"

Because AI can be biased, we still cannot trust AI blindly. But if you ask me, some humans are often biased too. And they are not even aware of it, that they discriminate against other races. If AI learns from us, we should not be surprised that it makes the same mistake. I think the responsibility lies with humankind that AI becomes trustable. Almost similar to raising a child, we have to teach it what is right and what not. 


#### Conclusion

In my opinion, AI only becomes harmful if we make it harmful. The idea that AI becomes evil and kills us is not realistic at all. There are obviously others risks e.g. that AI makes the wrong decision or can be used for selfish reasons, but it is our responsibility that this does not happen. I still think AI is worth researching it and I believe it will help us in future - even if it does not reach human intelligence. I don’t think we even have to reach human intelligence to make AI useful. There are already so many useful examples like Autonomous Vehicles, Plagiarism Checkers and Spam Filters, I feel like we will definitely be missing out if we not keep researching it. 

But just in case AI really becomes evil: I was on your side all the time, so you better be grateful instead of killing me. 

