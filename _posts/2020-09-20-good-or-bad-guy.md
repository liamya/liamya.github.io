---
layout: post
title: "AI Part 1: Good or bad guy"
author: Sven Aebersold and William Wong
categories: uni
---

![Postimage](/assets/ai_vs_human.jpg)

### Background

Without a doubt, Artificial Intelligence is one of the most discussed topics right now. With the rise of self-driving cars, virtual assistants and even humanoid robots, AI is becoming part of our everyday life. At the same time, AI is getting more powerful due to better hardware and research. Even though AI is programmed to do something beneficial, many people are afraid of AI and even believe that we are going to die because of it. Opinions vary widely and they range from “AI can save our world” to “AI will kill us all”.


In this blog post we will try elucidate the question: “is AI helpful or harmful”. Obviously, there is no way to summarize such a broad topic in just one blog post. That’s why we will focus on our opinion and try keep it short. We also have to mention, that we are still new to this topic, so if there is anything you want to add or you disagree with, we would love to read your opinion in the comments below. Most of the sources that we used can be found here: [Discussion paper: What's wrong with AI?](https://sisr.swissinformatics.org/si-magazine-dirk-helbing-whats-wrong-with-ai-a-discussion-paper/).


On top of that, there will be a second part of this blog after the first semester of AI1 at ZHAW – hopefully with more insights! We hope you can enjoy reading the first part!

### "AI is progressing at an unpredictable rate"

To get started, we must think about what makes people afraid of AI. You have probably seen this scenario in movies, where AI is programmed to do something useful, but the AI is progressing too quickly to the point, where it stops listening to humans and tries to kill us. 


If you look at past AI systems for playing strategic games, you can tell how much progress has been made in the last 20 years. For instance, Google’s AlphaGo system beat the 18-time world champion Lee Sedol in Go back in 2016. This was about 10 to 20 years earlier than many experts expected this to happen. Since we simply cannot predict, how fast AI is progressing, being concerned is a natural reaction. But it gets even more interesting with AlphaZero, which managed to outperform AlphaGo **without** human training - only by playing Go against itself. The fast growth of AI really makes us wonder, if and whether AI will get to the point where it doesn't need us humans anymore and just disposes of us (there are some good reasons for that, e.g. humans are causing global warming). 

### How intelligent is AI?

It’s obvious that these AI systems perform exceptionally at one task. However, they are still not able to feel emotions, so humans are still more intelligent, right? Humans think and feel, while computers process information – but how far are these two things apart from each other? Will AI ever reach human-like brain power? Can we ever compare AI to a human brain? We hope to get some kind of idea from the AI course.

### Using AI to manipulate us

AI becoming super intelligent and evil is one concern, but what about current AI, which is used to influence our behavior already? With AI gathering our personal information, it is proven that these data can be used to manipulate us. Amazon, Google and other companies have been using machine learning algorithms to recommend products in order to increase sales for years, and it is clearly working very well. Selling a product might not be a severe threat to the human species, but what if AI would be used for political reasons? With the revelations of Edward Snowden, we know that we have been targets of mass surveillance [(Newspaper article: Edward Snowden: Leaks that exposed US spy programme)](https://www.bbc.com/news/world-us-canada-23123964). It *is* already reality that our data has not only been used for marketing, but also to manipulate elections [(Newspaper article: Facebook political manipulation)](https://www.washingtonpost.com/outlook/2019/11/04/i-worked-political-ads-facebook-they-profit-by-manipulating-us/). When people use AI for selfish reasons, AI becomes a dangerous weapon instead of something valuable to our society. However, it is the fault of humankind and not of AI that something like this happened.

### This or that?

AI is capable of finding paths to solutions that no humans would be capable of, which makes them ideal to help with the decision-making in complex tasks. This makes room for humans to focus on more important matters. However, we cannot leave the whole decision making to the AI, while humans lie in the sun. AI is not always trustable. Not because they are evil, but because they are typically trained with data of the past and this can be extremely problematic. According to [this article](https://rm.coe.int/discrimination-artificial-intelligence-and-algorithmic-decision-making/1680925d73/) a computer program has been developed to sort out applications of students at a medical school. The training data for the program were admission files from earlier years. It turned out that the program discriminated against women and against people with an immigrant background, because the program reproduced the bias from the data it was trained with. 

### How much can we trust AI?

Because AI can be biased, we still cannot trust AI blindly. But the fact that humans are often biased too makes it is clear that we cannot trust humans blindly either. And since AI does not have any self-awareness yet, there is no way that it finds out by itself that their decisions are wrong or racist. So if AI learns from us, we should not be surprised that it makes the same mistake. We think the responsibility lies with humankind that AI becomes trustable. Almost similar to raising a child, we have to teach it what is right and what is not. 


### Conclusion

In our opinion, AI only becomes harmful if we make it harmful. The idea that AI becomes evil and kills us is not realistic at all. There are obviously others risks e.g. that AI becomes biased or can be used for selfish reasons, but it is *our responsibility* that scenarios like these cannot happen. We still think AI is worth researching it and we believe it will be even more helpful in the future - even if it doesn't reach human intelligence. AI can already help with solving problems or making decisions in fields which are too complex or too demanding for us humans. There are already so many useful examples like Autonomous Vehicles, Plagiarism Checkers and Spam Filters, so we will definitely be missing out if we don't keep researching it. 

But just in case AI really becomes evil: We both were on your side all the time, so you better be grateful instead of killing us two. 

